# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

app:
  name: "Agentic Backend"
  base_url: "/agentic/v1"
  address: "127.0.0.1"
  port: 8000
  log_level: "info"
  reload: false
  reload_dir: "."

security:
  m2m:
    enabled: true
    client_id: "agentic"
    realm_url: "http://app-keycloak:8080/realms/app"
  user:
    enabled: true
    client_id: "app"
    realm_url: "http://app-keycloak:8080/realms/app"
  authorized_origins:
    - "http://localhost:5173"
  rebac:
    enabled: false
    type: spicedb
    endpoint: "localhost:50051"
    insecure: true

frontend_settings:
  feature_flags:
    # If true activate the backend and frontend modules in charge of K8
    # and frugality monitoring
    enableK8Features: false
    # If true activate support for an electronic warfare demonstration
    enableElecWarfare: false
  properties:
    logoName: "fred"
    siteDisplayName: "SmurfIA"

ai:
  # In production  activate the configuration persistence mechanism
  # that allow users to create/update agents at runtime and change
  # their configuration without redeploying the application.
  # Developers: you may prefer to set this to true to trust only your static configuration
  use_static_config_only: false

  # Number of past exchanges to restore when initializing an agent session
  # This setting is used to limit the amount of historical context
  # that is loaded into the agent at the beginning of a session. It typically occur after a restart of the application
  # or when an agent session is re-initialized for any reason.
  agentic_restore_max_exchanges: 20

  # Maximum number of agents that cached in memory for faster access (uses LRU eviction policy)
  max_concurrent_agents: 128

  # Base URL for the Knowledge Flow service
  knowledge_flow_url: "http://localhost:8111/knowledge-flow/v1"

  # Timeout settings for the client
  timeout:
    connect: 5 # Time to wait for a connection in seconds
    read: 15 # Time to wait for a response in seconds

  default_chat_model:
    # Required in .env:
    # - OPENAI_API_KEY
    # provider: "azure-openai"
    # name: "gpt-4o"
    # settings:
    #   azure_apim_base_url: "https://tehopenai.openai.azure.com/"
    #   azure_openai_api_version: "2024-06-01"
    # provider: "azure-apim"
    # name: "gpt-4o"
    # settings:
    #   azure_apim_base_url: "https://trustnest.azure-api.net"
    #   azure_apim_resource_path: "/genai-aoai-inference/v2"
    #   azure_openai_api_version: "2024-06-01"
    #   azure_tenant_id: "your-tenant-id"
    #   azure_ad_client_id: "your-client-id"
    #   azure_ad_client_scope: "api://your-client-id/.default"
    provider: "openai"
    name: "gpt-4o"
    settings:
      temperature: 0.0
      max_retries: 2
      request_timeout: 30

  # Default language model used for non-chat interactions. This one is optional
  # and if not set, the default_chat_model will be used as fallback.
  default_language_model:
    # Required in .env:
    # - OPENAI_API_KEY
    provider: "openai"
    name: "gpt-4o"
    settings:
      temperature: 0.0
      max_retries: 2
      request_timeout: 30

  recursion:
    recursion_limit: 40 # Number or max recursion use by the agents while using the chat_model
  agents:
    - name: "Appollo"
      type: "leader"
      class_path: "agentic_backend.academy.06_simple_leader.mini_llm_orchestrator.MiniLLMOrchestrator"
      enabled: true
    - name: "Georges"
      type: "agent"
      class_path: "agentic_backend.agents.generalist.generalist_expert.Georges"
      enabled: true
    - name: "Sammy"
      type: "agent"
      class_path: "agentic_backend.agents.sentinel.sentinel_expert.SentinelExpert"
      enabled: true
    - name: "Rico"
      type: "agent"
      class_path: "agentic_backend.agents.rags.rag_expert.Rico"
      chat_options:
        search_policy_selection: true
        libraries_selection: true
      enabled: true
    - name: "Tessa"
      type: "agent"
      class_path: "agentic_backend.agents.tabular.tabular_expert.Tessa"
      enabled: true
mcp:
  servers:
    - name: "mcp-knowledge-flow-mcp-tabular"
      transport: "streamable_http"
      url: "http://localhost:8111/knowledge-flow/v1/mcp-tabular"
      sse_read_timeout: 2000
      auth_mode: "user_token"
    - name: "mcp-knowledge-flow-opensearch-ops"
      transport: "streamable_http"
      url: "http://localhost:8111/knowledge-flow/v1/mcp-opensearch-ops"
      sse_read_timeout: 2000
      auth_mode: "user_token"
    - name: "mcp-kubernetes-server"
      transport: "streamable_http"
      url: "http://localhost:8081/mcp"
      sse_read_timeout: 2000
      auth_mode: "user_token"
    - name: "mcp-atlassian-jira-server"
      transport: "streamable_http"
      url: "http://localhost:8885/mcp"
      sse_read_timeout: 2000
      auth_mode: "no_token"

storage:
  postgres:
    host: localhost
    port: 5432
    database: fred
    username: admin

  opensearch:
    host: https://localhost:9200
    secure: true
    verify_certs: false
    username: admin

  feedback_store:
    type: "opensearch"
    index: feedback-index

  agent_store:
    type: "opensearch"
    index: agent-index

  session_store:
    type: "opensearch"
    index: session-index

  history_store:
    type: "opensearch"
    index: history-index

  kpi_store:
    type: "opensearch"
    index: kpi-index

  log_store:
    type: "opensearch"
    index: log-index
