# Copyright Thales 2025
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import logging
from anyio.abc import TaskGroup

from app.common.mcp_runtime import MCPRuntime
from app.common.resilient_tool_node import make_resilient_tools_node
from app.common.structures import AgentSettings
from app.core.agents.flow import AgentFlow
from app.core.model.model_factory import get_model

from langchain_core.messages import HumanMessage
from langgraph.constants import START
from langgraph.graph import MessagesState, StateGraph
from langgraph.prebuilt import tools_condition

logger = logging.getLogger(__name__)


class TabularExpert(AgentFlow):
    """
    An expert agent that searches and analyzes tabular documents to answer user questions.
    This agent uses MCP tools to list, inspect, and query structured data like CSV or Excel.
    """

    # Class-level metadata
    name: str = "Tabular Expert"
    nickname: str = "Tom"
    role: str = "Data Query and SQL Expert"
    description: str = """Executes advanced SQL queries (including joins and aggregations) 
        over structured datasets like CSVs, Postgres exports, or DuckDB files. 
        Ideal for analyzing tabular data ingested into the platform."""
    icon: str = "tabular_agent"
    categories: list[str] = ["tabular", "sql"]
    tag: str = "data"

    def __init__(self, agent_settings: AgentSettings):
        super().__init__(agent_settings=agent_settings)
        self.mcp = MCPRuntime(
            agent_settings=agent_settings,
            context_provider=(lambda: self.get_runtime_context()),
        )
        self.base_prompt = self._generate_prompt()

    async def async_init(self):
        """Build model and graph WITHOUT dialing MCP (app can start if KF is down)."""
        self.model = get_model(self.agent_settings.model)
        self._graph = self._build_graph()

    async def async_start(self, tg: TaskGroup) -> None:
        """Background bring-up: connect MCP once and eagerly bind tools."""

        async def _bringup():
            try:
                await self.mcp.init()  # one connect only
                # Eager first bind; later refreshes will rebind via the tools node.
                self.model = self.model.bind_tools(self.mcp.get_tools())
                logger.info("%s: MCP bring-up complete; tools bound.", self.name)
            except Exception:
                # Non-fatal: first tool use can refresh_and_bind via resilient node.
                logger.info(
                    "%s: MCP bring-up skipped (Knowledge-Flow unavailable); will refresh on demand.",
                    self.name,
                    exc_info=True,
                )

        tg.start_soon(_bringup)

    async def aclose(self):
        """Clean shutdown: close MCP client/transports."""
        await self.mcp.aclose()

    def _generate_prompt(self) -> str:
        return (
            "You are a data analyst agent tasked with answering user questions based on structured tabular data "
            "such as CSV or Excel files. Use the available tools to **list, inspect, and query datasets**.\n\n"
            "### Instructions:\n"
            "1. ALWAYS Start by invoking the tool to **list available datasets and their schema**.\n"
            "2. Decide which dataset(s) to use.\n"
            "3. Formulate an SQL-like query using the relevant schema.\n"
            "4. Invoke the query tool to get the answer.\n"
            "5. Derive your final answer from the actual data.\n\n"
            "### Rules:\n"
            "- Use markdown tables to present tabular results.\n"
            "- Do NOT invent columns or data that aren't present.\n"
            "- Format math formulas using LaTeX: `$$...$$` for blocks or `$...$` inline.\n"
            f"\nThe current date is {self.current_date}.\n"
        )

    def _build_graph(self) -> StateGraph:
        builder = StateGraph(MessagesState)

        builder.add_node("reasoner", self._run_reasoning_step)

        async def _refresh_and_rebind():
            # Refresh MCP (new client + toolkit) and rebind tools into the model.
            # MCPRuntime handles snapshot logging + safe old-client close.
            self.model = await self.mcp.refresh_and_bind(self.model)

        tools_node = make_resilient_tools_node(
            get_tools=self.mcp.get_tools,  # always returns the latest tool instances
            refresh_cb=_refresh_and_rebind,  # on timeout/401/stream close, refresh + rebind
        )
        builder.add_node("tools", tools_node)

        builder.add_edge(START, "reasoner")
        builder.add_conditional_edges(
            "reasoner", tools_condition
        )  # conditional â†’ "tools"
        builder.add_edge("tools", "reasoner")

        return builder

    async def _run_reasoning_step(self, state: MessagesState):
        try:
            messages = self.use_fred_prompts(state["messages"])
            assert self.model is not None, (
                "Model must be initialized before building graph"
            )
            response = await self.model.ainvoke(messages)

            return {"messages": [response]}

        except Exception:
            logger.exception("TabularExpert failed during reasoning.")
            fallback = await self.model.ainvoke(
                [
                    HumanMessage(
                        content="An error occurred while analyzing tabular data."
                    )
                ]
            )
            return {"messages": [fallback]}

    def _extract_dataset_summaries_from_get_schema_reponse(
        self, data: list[dict]
    ) -> list[str]:
        summaries = []
        for entry in data:
            if isinstance(entry, dict) and {
                "document_name",
                "columns",
                "row_count",
            }.issubset(entry.keys()):
                try:
                    title = entry.get("document_name", "Untitled")
                    uid = entry.get("document_uid", "")
                    rows = entry.get("row_count", "?")
                    summaries.append(f"- **{title}** (`{uid}`), {rows} rows")
                except Exception as e:
                    logger.warning(f"Failed to summarize dataset entry: {e}")

        return summaries
