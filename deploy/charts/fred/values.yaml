# Unified values.yaml

global:
  kubeconfig: ""
  create_index:
    enabled: true
    image: "alpine:3.22"
  persistence:
    enabled: false                   # if true = Enable the creation of PVC when duckdb is used - Recommended TRUE
    dynamic: false                   # if true = let the PVCs create PVs if possible and do not create them manually 
    accessModes: "ReadWriteOnce"
    reclaimPolicy: "Retain"
    storageClass: "local-path"       # if empty = default storage class
    hostPath: "/mnt/fred-data"       # only used if dynamic=false & storageClass=local-path, remind to create this directory on your host

applications:

  agentic-backend:
    enabled: true
    applicationName: agentic-backend
    deployment:
      enabled: true
    statefulset:
      enabled: false
    job:
      enabled: false
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
    image:
      repository: ghcr.io/thalesgroup/fred-agent/agentic-backend
      tag: "0.1"
      pullPolicy: IfNotPresent
    command:
      enabled: true
      data:
        - "uvicorn"
        - "app.main:create_app"
        - "--factory"
        - "--host"
        - "0.0.0.0"
        - "--port"
        - "8000"
        - "--log-level"
        - "info"
        - "--loop"
        - "asyncio"    
    env:
      - name: CONFIG_FILE
        value: "/app/config/configuration.yaml"
    ports:
      - name: http
        containerPort: 8000
    service:
      annotations: {}
      extraLabels: {}
      type: ClusterIP
      ports:
        - name: http
          port: 80
          targetPort: 8000
    ingress:
      enabled: false
      className: ""
      hosts: []
    volumeMounts:
      - name: agentic-backend-vol
        mountPath: /app/config/configuration.yaml
        subPath: configuration.yaml
      - name: agentic-backend-env-vol
        mountPath: /app/config/.env
        subPath: .env
      - name: agentic-backend-kube-vol
        mountPath: /home/fred-user/.kube/config
        subPath: kubeconfig
    volumes:
      - name: agentic-backend-vol
        configMap:
          name: agentic-backend-back
      - name: agentic-backend-env-vol
        secret: 
          secretName: agentic-backend-env
      - name: agentic-backend-kube-vol
        configMap:
          name: agentic-backend-kube
          items:
            - key: kubeconfig
              path: kubeconfig
    probes:
      lifecycle:
        enabled: false
      livenessProbe:
        enabled: true
        data:
          httpGet:
            path: /agentic/v1/healthz
            port: 8000
      readinessProbe:
        enabled: true
        data:
          httpGet:
            path: /agentic/v1/ready
            port: 8000
      startupProbe:
        enabled: false
    securityContext:
      allowPrivilegeEscalation: false
      capabilities:
        drop:
        - "ALL"
      runAsUser: 1000
      runAsNonRoot: true
      seccompProfile:
        type: RuntimeDefault
    serviceAccount:
      annotations: {}
      labels: {}
      automountServiceAccountToken: true
      rbac:
        enabled: true
        permissions:
          namespaced:
            - apiGroups: [""]
              resources: ["pods", "configmaps", "secrets"]
              verbs: ["get", "list", "watch"]
            - apiGroups: ["apps"]
              resources: ["deployments", "replicasets"]
              verbs: ["get", "list", "watch", "create", "update", "patch"]
            - apiGroups: [""]
              resources: ["events"]
              verbs: ["create"]
          cluster:
            - apiGroups: [""]
              resources: ["nodes"]
              verbs: ["get", "list", "watch"]
    kubeconfig:
      enabled: true
    configuration_type:
      backend: true
      frontend: false
    configuration:
      app:
        name: "Agentic Backend"
        base_url: "/agentic/v1"
        address: "127.0.0.1"
        port: 8000
        log_level: "info"
        reload: false
        reload_dir: "."
      security:
        m2m:
          enabled: true
          client_id: "agentic"
          realm_url: "http://idp.dev.fred.thalesgroup.com/realms/app"
        user:
          enabled: true
          client_id: "app"
          realm_url: "http://idp.dev.fred.thalesgroup.com/realms/app"
        authorized_origins:
          - "http://fred.dev.fred.thalesgroup.com:80"
      frontend_settings:
        feature_flags:
          # If true activate the backend and frontend modules in charge of K8
          # and frugality monitoring
          enableK8Features: false
          # If true activate support for an electronic warfare demonstration
          enableElecWarfare: false
        properties:
          logoName: "fred"
      ai:
        knowledge_flow_url: "http://knowledge-flow-backend:8111/knowledge-flow/v1"
        # Timeout settings for the client
        timeout:
          connect: 5  # Time to wait for a connection in seconds
          read: 15    # Time to wait for a response in seconds
        default_chat_model:
          # Required in .env:
          # - OPENAI_API_KEY
          provider: "openai"
          name: "gpt-4o"
          settings:
            temperature: 0.0
            max_retries: 2
            request_timeout: 30
        recursion:
          recursion_limit: 40 # Number or max recursion use by the agents while using the chat model
        agents:
        - name: "Samy"
          type: "agent"
          class_path: "app.agents.sentinel.sentinel_expert.SentinelExpert"
          enabled: false
          role: "Opensearch instance monitoring expert"
          tags: ["monitoring"]
          chat_model: {}
          description: >
            An expert in monitoring and managing Opensearch instances.
            Samy can analyze performance metrics, identify issues, and provide recommendations for optimization.
          mcp_servers:
            - name: knowledge-flow-mcp-server
              transport: streamable_http
              url: http://knowledge-flow-backend:8000/knowledge-flow/v1/mcp-opensearch-ops
              sse_read_timeout: 2000
        - name: "Georges"
          type: "agent"
          class_path: "app.agents.generalist.generalist_expert.Georges"
          enabled: true
          role: "Generalist Assistant"
          tags: ["general"]
          chat_model: {}
          description: >
            A generalist assistant that can handle a wide range of tasks.
            He is the default assistant that can handle any task that does not require a specialized assistant.
        - name: "Tessa"
          type: "agent"
          role: "Data Query and SQL Expert"
          class_path: "app.agents.tabular.tabular_expert.Tessa"
          enabled: true
          tags: ["data"]
          chat_model: {}
          description: >
            An expert in querying databases and generating SQL queries.
            Tessa can assist with data retrieval, manipulation, and analysis tasks.
          mcp_servers:
            - name: knowledge-flow-mcp-server
              transport: streamable_http
              url: http://knowledge-flow-backend:8000/knowledge-flow/v1/mcp-tabular
              sse_read_timeout: 2000
        - name: "Rico"
          type: "agent"
          role: "Document Retrieval Expert"
          class_path: "app.agents.rags.rag_expert.Rico"
          enabled: true
          tags: ["documents"]
          chat_model: {}
          description: >
            An expert in retrieving and processing documents using retrieval-augmented generation techniques.
            Rico can help with tasks that involve understanding and utilizing large document collections.
        - name: "Brontë"
          type: "agent"
          role: "Content Generator Expert"
          class_path: "app.agents.content_generator.content_generator_expert.ContentGeneratorExpert"
          enabled: false
          tags: ["content"]
          chat_model: {}
          description: >
            An expert in generating content based on templates and knowledge from the knowledge-flow backend.
            Brontë can assist with creating various types of content efficiently.
          mcp_servers:
            - name: knowledge-flow-mcp-server
              transport: streamable_http
              url: http://knowledge-flow-backend:8000/knowledge-flow/v1/mcp-resources
              sse_read_timeout: 2000
        - name: "Rico Senior"
          type: "agent"
          role: "Advanced Document Retrieval Expert"
          class_path: "app.agents.rags.advanced_rag_expert.AdvancedRico"
          enabled: false
          tags: ["documents"]
          chat_model: {}
          description: >
            An advanced expert in retrieving and processing documents using enhanced retrieval-augmented generation techniques.
            Rico Senior is capable of handling more complex document-related tasks with improved accuracy.
          # settings:
          #   chunk_size: 512
          #   chunk_overlap: 64
          mcp_servers:
            - name: knowledge-flow-mcp-server
              transport: streamable_http
              url: http://knowledge-flow-backend:8000/knowledge-flow/v1/mcp-advanced-rag
              sse_read_timeout: 2000

      storage:
        postgres:
          host: localhost
          port: 5432
          database: fred
          username: admin
        opensearch:
          host: https://localhost:9200
          secure: true
          verify_certs: false
          username: admin
        feedback_store:
          type: "duckdb"
          duckdb_path: "~/.fred/agentic/feedback.duckdb"

        agent_store:
          type: "duckdb"
          duckdb_path: "~/.fred/agentic/agent.duckdb"

        session_store:
          type: "duckdb"
          duckdb_path: "~/.fred/agentic/session.duckdb"

        history_store:
          type: "duckdb"
          duckdb_path: "~/.fred/agentic/history.duckdb"

        kpi_store:
          type: "log"
          level: "INFO"

    dotenv:
      AZURE_OPENAI_API_KEY: ""
      KEYCLOAK_AGENTIC_CLIENT_SECRET: ""
      OPENAI_API_KEY: ""
      OPENSEARCH_PASSWORD: ""

  frontend:
    enabled: true
    applicationName: frontend
    deployment:
      enabled: true
    statefulset:
      enabled: false
    job:
      enabled: false
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
    image:
      repository: ghcr.io/thalesgroup/fred-agent/frontend
      tag: "0.1"
      pullPolicy: IfNotPresent
    command:
      enabled: false
    env:
      - name: VITE_ALLOWED_HOSTS
        value: "fred.dev"
      - name: VITE_BACKEND_URL_KNOWLEDGE
        value: "http://knowledge-flow-backend.dev.fred.thalesgroup.com"
      - name: VITE_USE_AUTH
        value: "true"
    ports:
      - name: http
        containerPort: 8080
    service:
      annotations: {}
      extraLabels: {}
      type: ClusterIP
      ports:
        - name: http
          port: 80
          targetPort: 8080
    ingress:
      enabled: true
      className: "nginx"
      hosts:
        - host: fred.dev.fred.thalesgroup.com
          paths:
            - path: /
              pathType: Prefix
              service:
                name: frontend
                port: 80
            - path: /agentic
              pathType: Prefix
              service:
                name: agentic-backend
                port: 80
            - path: /knowledge-flow
              pathType: Prefix
              service:
                name: knowledge-flow-backend
                port: 8000
      tls:
        - secretName: frontend-crt
          hosts:
            - fred.dev.fred.thalesgroup.com
    volumeMounts:
      - name: frontend-config-vol
        mountPath: /usr/share/nginx/html/config.json
        subPath: config.json
      - name: frontend-config-vol
        mountPath: /usr/share/nginx/html/keycloak.json
        subPath: keycloak.json
    volumes:
      - name: frontend-config-vol
        configMap:
          name: frontend-front
    probes:
      lifecycle:
        enabled: true
      livenessProbe:
        enabled: true
        data:
          httpGet:
            path: /healthz.html
            port: 8080
      readinessProbe:
        enabled: true
        data:
          httpGet:
            path: /ready.html
            port: 8080
      startupProbe:
        enabled: false
    securityContext:
      allowPrivilegeEscalation: false
      capabilities:
        drop:
        - "ALL"
      runAsNonRoot: true
      seccompProfile:
        type: RuntimeDefault
    serviceAccount:
      annotations: {}
      labels: {}
      automountServiceAccountToken: true
      rbac:
        enabled: true
        permissions: {}
    kubeconfig:
      enabled: false
    configuration_type:
      frontend: true
      backend: false
    configuration:
      config_json:
        backend_url_api: "http://fred.dev.fred.thalesgroup.com"
        backend_url_knowledge: "https://fred.dev.fred.thalesgroup.com"
        websocket_url: "ws://fred.dev.fred.thalesgroup.com/fred/chatbot/query"

  knowledge-flow-backend:
    enabled: true
    applicationName: knowledge-flow-backend
    deployment:
      enabled: true
    statefulset:
      enabled: false
    job:
      enabled: false
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
    image:
      repository: ghcr.io/thalesgroup/fred-agent/knowledge-flow-backend
      tag: "0.1"
    command:
      enabled: true
      data:
        - "uvicorn"
        - "app.main:create_app"
        - "--factory"
        - "--host"
        - "0.0.0.0"
        - "--port"
        - "8111"
        - "--log-level"
        - "info"
        - "--loop"
        - "asyncio"
    env:
      - name: LOG_LEVEL
        value: "INFO"
      - name: CONFIG_FILE
        value: "/app/config/configuration.yaml"
    ports:
      - name: http
        containerPort: 8111
      - name: https
        containerPort: 8443
    service:
      annotations: {}
      extraLabels: {}
      type: ClusterIP
      ports:
        - name: "http"
          port: 8000
          targetPort: 8111
          protocol: TCP
        - name: "https"
          port: 8443
          targetPort: 8443
          protocol: TCP
    ingress:
      enabled: false
      className: ""
      hosts: []
    volumeMounts:
      - name: knowledge-flow-backend-vol
        mountPath: /app/config/configuration.yaml
        subPath: configuration.yaml
      - name: knowledge-flow-backend-env-vol
        mountPath: /app/config/.env
        subPath: .env
    volumes:
      - name: knowledge-flow-backend-vol
        configMap:
          name: knowledge-flow-backend-back
      - name: knowledge-flow-backend-env-vol
        secret: 
          secretName: knowledge-flow-backend-env
    probes:
      lifecycle:
        enabled: false
      livenessProbe:
        enabled: true
        data:
          failureThreshold: 10
          httpGet:
            path: /knowledge-flow/v1/healthz
            port: 8111
          periodSeconds: 10
      readinessProbe:
        enabled: true
        data:
          failureThreshold: 10
          httpGet:
            path: /knowledge-flow/v1/ready
            port: 8111
          periodSeconds: 10
      startupProbe:
        enabled: false
    securityContext:
      allowPrivilegeEscalation: false
      capabilities:
        drop:
        - "ALL"
      runAsUser: 1000
      runAsNonRoot: true
      seccompProfile:
        type: RuntimeDefault
    serviceAccount:
      annotations: {}
      labels: {}
      automountServiceAccountToken: true
      rbac:
        enabled: true
        permissions: {}
    kubeconfig:
      enabled: false
    configuration_type:
      backend: true
      frontend: false
    configuration:
      app:
        name: "Knowledge Flow Backend"
        base_url: "/knowledge-flow/v1"
        address: "127.0.0.1"
        port: 8111
        log_level: "info"
        reload: false
        reload_dir: "."
      processing:
        generate_summary: true
        use_gpu: true
        process_images: true
      security:
        m2m:
          enabled: true
          client_id: "knowledge-flow"
          realm_url: "http://idp.dev.fred.thalesgroup.com/realms/app"
        user:
          enabled: true
          client_id: "app"
          realm_url: "http://idp.dev.fred.thalesgroup.com/realms/app"
        authorized_origins:
          - "http://fred.dev.fred.thalesgroup.com:80"
      scheduler:
        enabled: true
        backend: "temporal"
        temporal:
          host: "localhost:7233"
          namespace: "default"
          task_queue: "ingestion"
          workflow_prefix: "pipeline"
          connect_timeout_seconds: 5
      input_processors:
        - prefix: ".pdf"
          class_path: app.core.processors.input.pdf_markdown_processor.pdf_markdown_processor.PdfMarkdownProcessor
        - prefix: ".docx"
          class_path: app.core.processors.input.docx_markdown_processor.docx_markdown_processor.DocxMarkdownProcessor
        - prefix: ".pptx"
          class_path: app.core.processors.input.pptx_markdown_processor.pptx_markdown_processor.PptxMarkdownProcessor
        - prefix: ".csv"
          class_path: app.core.processors.input.csv_tabular_processor.csv_tabular_processor.CsvTabularProcessor
        - prefix: ".txt"
          class_path: app.core.processors.input.text_markdown_processor.text_markdown_processor.TextMarkdownProcessor
        - prefix: ".md"
          class_path: app.core.processors.input.markdown_markdown_processor.markdown_markdown_processor.MarkdownMarkdownProcessor
        - prefix: ".xlsm"
          class_path: app.core.processors.input.pps_tabular_processor.pps_tabular_processor.PpsTabularProcessor
        - prefix: ".jsonl"
          class_path: app.core.processors.input.jsonl.jsonl_markdown_processor.JsonlMarkdownProcessor
      content_storage:
        type: local
        root_path: ~/.fred/knowledge-flow/content-storage
      document_sources:
        fred:
          type: push
          description: "Documents manually uploaded by users"
        local:
          type: pull
          provider: local_path
          base_path: ~/Documents/Fred
          description: "Personal local documents available for pull-mode ingestion"
      embedding_model:
        provider: openai
        name: text-embedding-3-large
        settings: {}
        type: "openai"
      chat_model:
        provider: openai        # openai | azure | ollama
        name: gpt-4o-mini       # azure: deployment name, ollama: 'qwen2.5:3b-instruct' etc.
        settings:
          # openai: nothing else required (keys in .env)
          # azure: { endpoint: "...", api_version: "2024-08-01-preview" }
          # ollama: { base_url: "http://localhost:11434"
      storage:
        postgres:
          host: localhost
          port: 5432
          database: fred
          username: admin
        opensearch:
          host: https://localhost:9200
          secure: true
          verify_certs: false
          username: admin
        catalog_store:
          type: "duckdb"
          duckdb_path: "~/.fred/knowledge-flow/catalog.duckdb"
        prompt_store:
          type: "duckdb"
          duckdb_path: "~/.fred/knowledge-flow/prompt.duckdb"
        resource_store:
          type: "duckdb"
          duckdb_path: "~/.fred/knowledge-flow/resource.duckdb"
        kpi_store:
          type: "log"
          level: "INFO"
        tag_store:
          type: "duckdb"
          duckdb_path: "~/.fred/knowledge-flow/tag.duckdb"
        metadata_store:
          type: "duckdb"
          duckdb_path: "~/.fred/knowledge-flow/metadata.duckdb"

        vector_store:
          type: in_memory
        tabular_stores:
          base_database:                            # Minimal configuration to enable CSV document ingestion
            type: "sql"
            driver: "duckdb"
            database: "base_database"
            path: "~/.fred/knowledge-flow/db.duckdb"
            mode: "read_and_write"

    dotenv:
      KEYCLOAK_KNOWLEDGE_FLOW_CLIENT_SECRET: ""
      MINIO_SECRET_KEY: ""
      OPENAI_API_KEY: ""
      OPENSEARCH_PASSWORD: ""