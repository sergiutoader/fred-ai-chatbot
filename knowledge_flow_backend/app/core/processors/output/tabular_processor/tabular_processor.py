# Copyright Thales 2025
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import logging
import pandas as pd
import re
from pandas._libs.tslibs.nattype import NaTType
from langchain.schema.document import Document
import io
import dateparser


from app.application_context import ApplicationContext
from app.common.utils import sanitize_sql_name
from app.common.document_structures import DocumentMetadata, ProcessingStage
from app.core.processors.output.vectorization_processor.vectorization_utils import load_langchain_doc_from_metadata
from app.core.processors.output.base_output_processor import BaseOutputProcessor, TabularProcessingError

logger = logging.getLogger(__name__)


def _parse_date(value: str) -> pd.Timestamp | NaTType:
    dt = dateparser.parse(value, settings={"PREFER_DAY_OF_MONTH": "first", "RETURN_AS_TIMEZONE_AWARE": False})
    if dt:
        return pd.to_datetime(dt)
    return pd.NaT


class TabularProcessor(BaseOutputProcessor):
    """
    A pipeline for processing tabular data.
    """

    def __init__(self):
        self.csv_input_store = ApplicationContext.get_instance().get_csv_input_store()

        logger.info("Initializing TabularPipeline")

    def process(self, file_path: str, metadata: DocumentMetadata) -> DocumentMetadata:
        try:
            logger.info(f"Processing file: {file_path} with metadata: {metadata}")

            document: Document = load_langchain_doc_from_metadata(file_path, metadata)
            logger.debug(f"Document loaded: {document}")
            if not document:
                raise ValueError("Document is empty or not loaded correctly.")

            df = pd.read_csv(io.StringIO(document.page_content))
            table_name = sanitize_sql_name(metadata.document_name.rsplit(".", 1)[0])
            df.columns = [sanitize_sql_name(col) for col in df.columns]

            for col in df.columns:
                if df[col].dtype == object:
                    sample_values = df[col].dropna().astype(str).head(10)
                    parsed_samples = sample_values.map(_parse_date)
                    success_ratio = parsed_samples.notna().mean()
                    if success_ratio > 0.6 and parsed_samples.nunique() > 1:
                        logger.info(f"ðŸ•’ Parsing column '{col}' as datetime (score: {success_ratio:.2f})")
                        df[col] = df[col].astype(str).map(_parse_date)

            logger.debug(f"document {document}")

            try:
                if self.csv_input_store is None:
                    raise RuntimeError("csv_input_store is not initialized")
                result = self.csv_input_store.save_table(table_name, df)
                logger.debug(f"Document added to Tabular Store: {result}")
            except Exception as e:
                logger.exception("Failed to add documents to Tabular Storage")
                raise TabularProcessingError("Failed to add documents to Tabular Storage") from e

            metadata.mark_stage_done(ProcessingStage.SQL_INDEXED)
            return metadata

        except Exception as e:
            logger.exception("Unexpected error during tabular processing")
            raise TabularProcessingError("Tabular processing failed") from e
